---
layout: post
title: 《Java并发编程实战》8.线程池的使用
tags:
  - 读书笔记
categories:
  - 《Java并发编程实战》读书笔记
abbrlink: 50fa6f64
date: 2020-05-04 15:53:00
---

![image-20200810073223274](https://xuyanxin-blog-bucket.oss-cn-beijing.aliyuncs.com/blog/20200810073224.png)

**第6章**

-  {% post_link 读书笔记/java编程实战/6/6.任务执行（上） 任务执行（上） %}  

介绍了**「任务执行框架」**，它的作用不仅是 「简化`任务`与`线程``生命周期`的管理」，还提供了「`简单灵活`」的方式将任务的`提交`与`执行策略`**解耦**。

**第7章**

-  {% post_link 读书笔记/java编程实战/7/7.取消与关闭（上） 7.取消与关闭（上） %} 

介绍了在「实际应用程序」中使用`任务执行框架`时出现的一些与`服务生命周期`相关的细节问题。

本章的内容：

- **线程池「`基本配置`」**选项
- **线程池「`调优`」**高级选项
- 使用**任务执行框架时可能存在的`危险**`
- `Executor` 高级使用示例

<!-- more -->	

### 8.1 在任务与执行策略之间的隐性耦合

`Executor` 框架可以将任务的提交与执行策略 **「解耦」**。 就像许多对复杂过程的解耦操作一样，这种论断有些「言过其实」。【也就是这里的解耦并不是那么彻底，还是存在许多问题？】

虽然 `Executor`  框架为制定和修改执行任务策略提供了 相当大的 「灵活性」，但并非所有任务都适用于任何执行策略，某些**特殊类型的任务需要指定特别的执行策略**：

- `依赖性任务`：

大多数行为正确的任务都是**「独立」**的：它们`不依赖`其他任务的**「执行时序」**、**「执行结果」** 或 **其他效果**。 当在线程池中执行**「独立」**任务时，可以随意改变**「线程池」**的`大小` 和 `配置`，而这些修改只会**影响任务的执行效率**，而**不会产生其他影响**。

 但是如果线程池中存在`「依赖性任务」`，那么就对**执行策略**有了隐含的要求：**此时必须小心地维持执行策略，避免产生`「活跃性问题」`**。

- 使用`线程封闭机制`的任务：

与**「线程池」**相比，单线程的 `Executor` 能够对**并发性**做出更强的**承诺**。 它们能确保任务不会并发地执行，使你能够**放宽代码对线程安全的要求**。

对象可以「封闭」在`任务线程`中，使得在该线程中执行的任务在访问该对象时「不需要同步」，即使这些资源不是线程安全的也没有问题。

这种情形将任务与执行策略形成了**隐式耦合**——任务要求其执行所在的 `Executor` 是单线程的。（这个要求并不需要这么严格，但是需要确保任务不会并发执行，并提供足够的同步机制，使得一个任务对内存的作用对于下一个任务`一定是可见`的。 而这正是 `newSingleThreadExecutor` 提供的保证。）

如果将 `Executor` 从`单线程`改为**「线程池」**环境，那么将失去线程安全性。

- 对**响应时间** `敏感` 的任务：

`GUI` 应用程序对于响应时间是敏感的：如果用户在点击按钮后需要很长的延迟才能得到可见的反馈，那么他们一定会感到不满。

如果将一个运行时间较长的任务提交到单线程的 `Executor` 中，或者将多个运行时间较长的任务提交到一个只包含少量线程的线程池中，那么将降低该 `Executor` 管理的服务的响应性。

**【↑ 前者导致单线程执行时间过长，后面的任务没法即时执行，后者由于线程太少，导致某些任务也无法执行，从而响应时间过长。】**

- 使用 `ThreadLocal` 的任务。

`ThreadLocal` 使每个线程都拥有某个变量的一个私有版本。 然而只要 「条件允许」，Executor 可以自由地重用这些线程。

在标准的 `Executor` 实现中，当执行需求较低时，将回收**「空闲」**线程，当需求增加时，将添加新的线程，并且如果从任务中抛出了一个「未检查」的异常，将用一个新的工作者线程来替代抛出异常的线程。

**只有当线程本地值的声明周期受限于任务的生命周期时，在线程池中使用 ThreadLocal 才有意义，而在线程池的线程中不应该使用 ThreadLocal 在任务之间传递值。**

只有当任务都是`「相同类型」`，并且`「相互独立」`时，线程池性能才能达到最佳。 **<--- 线程池最佳性能对于执行任务的要求**。

如果将运行时间较长与运行时间较短的任务混合在一起，那么除非线程池**「很大」**，否则将可能造成`「拥塞」`。

如果提交的任务「依赖」于其他任务，那么除非线程池**「无限大」**，否则将可能造成`「死锁」`。

幸运的是，基于网络的典型服务器应用程序中 —— **网页服务器**、**邮件服务器**，以及**文件服务器**等，**它们的请求通常都是同类型并且互相独立的。**

> 在一些任务中，需要拥有或排除某种特定的执行策略。**如果某些任务以来于其他任务，那么会要求线程池足够大，从而确保它们以来任务不会被放入「等待队列」或被「拒绝」，**
>
> 采用**线程封闭机制的任务需要串行执行**。通过将这些需求**写入文档**，将来的代码维护人员就不会由于使用了某种不合适的执行策略而破坏`「安全性」`或`「活跃性」`

#### 8.1.1 线程饥饿死锁

**在线程池中，如果任务依赖其他任务，那么可能产生死锁。**

**在`「单线程」` `Executor`中，如果一个任务将另一个任务提交到同一个 `Executor`，并且「等待使用这个被提交任务的结果」，那么通常会引发死锁。**

**【↑ 常见的产生死锁的场景】**

第二个任务停留在**「工作队列」**中，并等**待第一个任务完成**，而**第一个任务又无法完成，因为它在等待第二个任务的完成的结果**，也就是互相等待。

在`更大的线程池`中，如果所有正在执行任务的线程都由于等待其他仍在工作队列中的任务而阻塞，那么会发生同样的问题。这种现象被称为`线程饥饿死锁`（`Thread Starvation DeadLock`），只要线程池中的任务需要**无限期**地**等待**一些必须由池中**其他任务**才能**提供**的**「资源」**或**「条件」**，**例如某个任务等待另一个任务的返回值或执行结果，那么除非线程池足够大，否则将发生线程饥饿死锁。**

**程序清单 8-1** 的 `ThreadDeadLock` 中给出了线程饥饿死锁的示例。 `RenderPageTask` 向 `Executor` 提交了**两个任务**来获取网页的页眉和页脚，并绘制页面**，绘制页面任务需要等待获取页眉和页脚的任务结果**，然后将页眉、页面主题和页脚组合起来形成最终的页面。

如果使用单线程的 `Executor`，那么`ThreadDeadLock` 会经常发生死锁。

同样，如果线程池不够大，那么当多个任务通过 `栅栏（Barrier）`机制来彼此协调时，将导致线程饥饿死锁。

> **`程序清单 8-1`** 在 **单线程** `Executor` 中任务发生死锁（不要这么做）

```java
// 会经常发生死锁的例子
public class ThreadDeadLock {
    // 串行Executor
    ExecutorService exec = Executors.newSingleThreadExecutor();

    public class LoadFileTask implements Callable<String> {
        private final String fileName;

        public LoadFileTask(String fileName) {
            this.fileName = fileName;
        }

        @Override
        public String call() throws Exception {
            // 这里是读取 File 内容的业务逻辑；
            return "";
        }
    }

    public class RenderPage implements Callable<String> {


        @Override
        public String call() throws Exception {
            // 定义获取页眉和页脚任务的 Future 引用，用于获取其任务执行完的内容
            Future<String> header, footer;
            header = exec.submit(new LoadFileTask("header.html"));
            footer = exec.submit(new LoadFileTask("footer.html"));
            String page = renderBody();
            // 在这里将发生死锁，因为渲染页面的任务等待获取 header 和 footer 任务的结果
            return header.get() + page + footer.get();
        }

        private String renderBody() {
            // 这里是实际渲染页面的业务逻辑
            return "";
        }
    }
}
```

> 每当提交了一个**有依赖性的 `Executor` 任务**时，要清楚地知道可能出现**「线程饥饿」死锁**，因此需要在**代码**或**配置** `Executor` 的配置文件中**记录线程池的大小限制或配置限制**。

#### 8.1.2 运行时间较长的任务

`场景`：**线程池中的线程数量少于执行时间较长的任务的数量。**

`描述`：**如果线程池中线程数量不足，同时存在执行时间长的任务，则会降低整体程序的响应**。

`解决方案`：**限定任务等待资源的时间**。

`问题`：如果线程池中总是充满了被阻塞的任务，可能表明该**线程池的数量过小**。

`原文`：

> 如果任务**阻塞的时间过长**，那么即使不出现死锁，线程池的响应性也会变得糟糕。
>
> 执行时间较长的任务不仅会造成线程池堵塞，甚至还会增加执行时间较短任务的服务时间。
>
> 如果线程池中线程的数量远小于在稳定状态下执行时间较长任务的数量，那么最后可能所有线程都在运行这些执行时间较长的任务，从而影响整体的响应性。
>
> 有一项技术可以缓解执行时间较长任务造成的影响：**限定任务等待资源的时间**，不要无限制地等待资源。
>
> 在平台类库的大多数可阻塞方法中，都同时定义了 `「限时版本」`和`「无限时」`版本。
>
> 例如：`Thread.join`、`BlockingQUeue.put`、`CountDownLatch.await` 以及 `Selector.select` 等。
>
> 如果等待超时，那么可以将该任务标记为失败，然后中止任务或者将任务重新放回队列。
>
> 这样无论任务最终是否成功，都能确保其余任务继续执行，并将线程释放以执行一些能更快完成的任务。 如果在线程池中总是充满了被阻塞的任务，那么也可能表明线程池的规模较小。

### 8.2 设置线程池的大小

线程池的理想大小取决于被提交的任务的类型以及所部署的系统的特性。在代码中通常不会固定线程池的大小，而是通过配置来动态的提供属性，或者根据 `Runtime.availableProcessor`来动态的计算。

设置线程池只需要避免「过大」和「过小」这两种极端情况。 

**线程池过大**：大量的线程将在相对很少的 `CPU` 和 `内存` 资源上发生竞争，这会导致更高的内存使用量，而且还可能导致资源的耗尽。

**线程池过小**：导致许多空闲的处理无法执行工作，降低吞吐率。

正确设置线程池大小的前提：分析 `计算环境`、`资源预算`、`任务特性`。

`计算环境：`

- 部署系统中 `CPU的数量`
- `内存`的大小

`任务特性`：

- `计算密集`型任务
- `I/O 密集`型任务
- 二者皆是

`资源`：

- 是否需要类似 `JDBC` 的稀缺资源

如果需要执行异构的，不同类型的任务，并且任务之间的行为相差很大，那么应该考虑使用 `多个`线程池，从而使每个线程池根据各自的工作负载来进行调整。

`计算密集`型任务：线程池的大小设置为 `CPU数量+1` 个线程时，通常能实现**最优利用率**。（即使当计算密集型的线程偶尔由于`「页缺失故障」`或者其他原因暂停时，这个"额外"的线程也能确保 CPU时钟周期不会被浪费。

包含 `I/O 操作`或者其他 **阻塞**类型操作的任务：对于包含 `I/O 操作`或者其他`阻塞操作`的任务，由于线程并不会一直执行，因此线程池的规模应该「更大」。

正确设置线程池大小的前提：估算任务的`「等待时间」`与`「计算时间」`的 `比值`。这种估算不需要太过精确，并且可以通过一些分析或监控工具来获得。

调节线程池大小的另一种方法：在某个 `「基准负载」`下，分别设置不同大小的线程池来运行应用程序，并观察 CPU 利用率的水平。

**↓是书中原始计算方式**

![](https://xuyanxin-blog-bucket.oss-cn-beijing.aliyuncs.com/blog/20200506192232.png)

可以看到有三个变量影响计算线程池线程数的变量： `CPU数量`、`CPU利用率`、`CPU计算时间与空闲时间的比值`。

影响线程池大小的资源：

- `CPU 周期`
- `内存`
- `文件句柄`
- `套接字句柄`
- `数据库连接`

这些资源综合在一起限制了线程池大小，计算除了 CPU 周期之外的线程数量更加简单：**资源量/单个任务消耗的资源量 = 可以设置的线程池大小上限。**

当任务需要通过某种资源池来管理资源时，例如 数据库连接，那么「线程池」和**「资源池」**的大小将会`互相影响。` 例如：每个任务都需要一个数据库连接，那么`连接池的大小就限制了线程池的大小。` 同样，当线程池中的任务是数据库连接的唯一使用者时，`线程池的大小将限制连接池的大小。`

### 8.3 配置 ThreadPoolExecutor

`ThreadPoolExecutor` 为一个 `Executor` 提供了 基本实现，这些  `Executor` 是由 `Executors` 中的 `newCachedThreadPool` 、`newFixedThreadPool`、和 `newSceduledThreadExecutor` 等工厂方法返回的。

`ThreadPoolExecutor` 是一个灵活的、稳定的线程池，运行进行各种定制。

如果默认的**「执行策略」**不能满足需求，可以通过 `ThreadPoolExecutor` 构造函数来实例化一个对象，并根据自己的需求进行定制，可以参考 `Executors` 的源代码来了解**默认配置下的执行策略**，然后**再以这些执行策略为基础进行修改**。

`ThreadPoolExecutor` 定义了很多构造函数，下面给出了最常见的形式：

```java
 public ThreadPoolExecutor(int corePoolSize,
                              int maximumPoolSize,
                              long keepAliveTime,
                              TimeUnit unit,
                              BlockingQueue<Runnable> workQueue,
                              ThreadFactory threadFactory,
                              RejectedExecutionHandler handler) {
        if (corePoolSize < 0 ||
            maximumPoolSize <= 0 ||
            maximumPoolSize < corePoolSize ||
            keepAliveTime < 0)
            throw new IllegalArgumentException();
        if (workQueue == null || threadFactory == null || handler == null)
            throw new NullPointerException();
        this.acc = System.getSecurityManager() == null ?
                null :
                AccessController.getContext();
        this.corePoolSize = corePoolSize;
        this.maximumPoolSize = maximumPoolSize;
        this.workQueue = workQueue;
        this.keepAliveTime = unit.toNanos(keepAliveTime);
        this.threadFactory = threadFactory;
        this.handler = handler;
    }
```

[ThreadPollExecutor Javadoc](https://docs.oracle.com/javase/1.5.0/docs/api/java/util/concurrent/ThreadPoolExecutor.html#ThreadPoolExecutor(int,%20int,%20long,%20java.util.concurrent.TimeUnit,%20java.util.concurrent.BlockingQueue,%20java.util.concurrent.ThreadFactory,%20java.util.concurrent.RejectedExecutionHandler))

#### 8.3.1 线程的创建与销毁

线程池的**基本大小**（`Core Pool Size`）、 **最大大小**（`Maximum Pool Size`）以及 **存活时间** 等因素共同负责线程的**「创建」** 与 **「销毁」**。

基本大小是线程池的目标大小 —— 在没有任务执行时「线程池的大小」。（在创建 `ThreadPoolExecutor`  的初期，线程并不会立即启动，而是等到有任务提交时才启动，除非调用 `prestartAllCoreThreads`）并且只有在工作队列满了的情况下才会创建超过这个数量的线程。

【开发有时会将线程池的基本大小 「设置为0」。，从而最终销毁工作者线程以免阻碍 JVM 退出。 

然而如果在线程池中没有使用 `SynchronousQueue` 作为其工作队列（例如在 `newCachedThreadPool` 中就是这种情况），那么这种方式将产生一些奇怪的行为。

- 如果线程池中的数量等于线程池的基本大小，那么仅当在工作队列已满的情况下 ThreadPo`olExecutor 才会创建新的线程。`

因此，如果线程池的基本大小为零，并且其工作队列有一定的容量，那么把任务提交给线程池时，只有当线程池的工作队列被填满后，才会开始执行任务，而这种行为通常并不是我们希望的。

在 `Java6` 中，可以通过 `allowCoreThreadTimeOut` 来使线程池中的所有线程超时。

对于一个大小有限的线程池，并且在该线程池中包含一个工作队列，如果希望这个线程池在没有任务的情况下能够销毁所有线程，那么可以启用这个特性并将基本大小设置为0。】

`↑ 什么时候回将线程池的基本大小设置为0，这样设置会带来什么样的影响，以及为什么要这样设置的理由。`

线程池的**最大大小表示可以同时活动的线程数量的上限**。如果某个线程的空闲时间超过了存活时间，那么将被标记为「可回收」的，并且**当线程池的当前大小超过基本大小时，这个线程将被终止**。（空闲线程被优先终止）

通过调节线程池的 「基本大小」 和 「存活时间」，可以帮助线程池回收空闲线程占用的资源，从而使得这些资源可以用于执行其他工作。（这也是一种折中的设计，因为回收空闲线程会产**生「额外的延迟」**，因为当需求增加时，必须创建新线程来满足需求，额创建线程需要时间与开销）

`newFixedThreadPool` 工厂方法将线程池的基本大小和最大大小设置为参数中指定的值，而且**创建的线程池不会超时**。

 `newCachedThreadPool` 工厂方法将线程池的最大大小设置为 `Integer.MAX_VALUE`，将`基本大小设置为零`，并将`超时时间设置为1分钟`，这种方法创建出来的线程池可以被**「无限扩展」**，并且当需求降低时会**「自动收缩」**。

其他形式线程池可以通过显式的 `ThreadPoolExecutor` 构造函数来构造。

#### 8.3.2 管理队列任务

在有限的线程池中会限制可并发执行的任务的数量。（单线程的 `Executor` 是一种值得注意的`特例`：它们能确保不会有任务并发执行，因为通过`单线程 Executor` 通过 **「线程封闭」**来实现**线程安全性**）

在 `6.1.2`  {% post_link 读书笔记/java编程实战/6/6.任务执行（上） 任务执行（上） %} 中曾经介绍过：如果**「无限制」**地创建线程，将导致**不稳定性**，其解决方案是通过采用**固定大小**的**线程池**（而不是为每个请求都创建一个新线程）来解决这个问题，然而这个解决方案并**不完整**。

在**高负载**的情况下**，应用程序仍然可能耗尽系统资源**，只是出现的概率比较小。

如果请求到达的速率超过了线程池处理请求的速率，那么新的请求将产生堆积，在线程池中，这些请求会在一个由 `Executor` 管理的 `Runnbale` 队列中等待，而不是像直接**创建线程那样去竞争 `CPU` 资源**。

通过**一个 `Runnable`** 和**一个链表节点**来表现一个**等待中的任务**，比使用线程来表示的开销低很多，但是当客户的请求提交速率超过了服务器的处理速率，仍然有可能耗尽资源。

即使请求的平均到达速率很稳定，也仍然会出现请求突增的情况。 尽管队列有助于缓解任务的突增问题，但如果任务**「持续高速」**地到来，那么最终还是会**「抑制」**请求的到达率以避免耗尽内存。（这类似与**通信网络**中的`流量控制`：可以**缓存一定量的数据**，但最终需要**通过某种方式告诉发送端停止发送数据**，或者**丢弃过多的数据并希望发送端空闲时重传被丢弃的数据**。）

甚至在耗尽内存之前，响应性能也将随着任务队列的增长而变的越来越糟糕。

`ThreadPoolExecutor` 允许提供一个 `BlockingQueue` 来保存等待执行的任务。 

基本的任务排队方法有`3`种：

- `无界队列`
- `有界队列`
- `同步移交队列（Synchronous Handoff）`

队列的选择与**其他的配置参数**有关，例如：`「线程池的大小」`。

`newFixedThreadPool` 和 `newSingleThreadExecutor` 在 **「默认」** 情况下将使用一个**「无界」**的 `LinkedBlockingQueue`。

如果**所有工作者线程都处于忙碌状态**，那么**任务将在队列中等候**。

如果任务**持续快速**地到达，并且**超过了线程池处理的速度**，那么队列将**「无限制」**地增加。

一种更稳妥的资源管理策略是使用 `「有界队列」`，例如 `ArrayBlockingQueue`，`有界的LinkedBlockingQueue`、`PriorityBlockingQueue`。

有界队列的意义在于：有助于避免资源耗尽情况的发生。

但是有界队列带来了新问题：队列填满后，新任务该怎样处理。（有许多 「饱和策略」，可以解决这个问题）

**在使用有界工作队列时，队列的大小与线程池的大小必须一起调节。**

如果**线程池较小，而队列较大**，那么有助于`减少内存使用量`，`降低 CPU使用率`，同时`减少上下文切换`，但**付出的代价是：「限制吞吐量」**。

对于非常大的，或者无界的 「线程池」，可以通过使用 `SynchronousQueue` 来避免任务排队，以及直接将任务从生产者移交给工作者线程。

`SynchronousQueue` **不是一个真正的队列，而是一种在线程之间进行移交的机制**。

要将一个元素放入 `SynchronousQueue` 中，必须有另一个线程正在等待接受这个元素。 如果没有线程正在等待，并且线程池的当前大小 小于 最大值，那么 `ThreadPoolExecutor` 将创建一个新的线程，否则根据「饱和策略」，这个任务将被拒绝。

使用直接移交的好处是更加高效，因为任务会直接移交给执行它的线程，而不是首先放在队列中，然后由工作者线程从 「队列」中「提取」该任务。

只有当线程池是**「无界」**的或者**「可以拒绝任务」**时，`SynchronousQueue` 才有**实际价值**。 

在 `newCachedThreadPool` **工厂方法**中就使用了 `SynchronousQueue`。

当使用像 `LinkedBlockingQueue` 或者 `ArrayBlockingQueue` 这样的 `FIFO`**（先进先出）**队列时**，任务的执行顺序与它们的到达顺序相同**。

如果想想进一步控制任务执行顺序，还可以使用 `PriorityBlockingQueue` ，这个队列根据「优先级」 来安排任务。

任务的**优先级**是通过「**自然顺序**」或 `Comparator` （如果任务实现了 `Comparator`） 来定义的。

> 对于 `Executor`，`newCachedThreadPool` 工厂方法是一种**很好的默认选择**，它能提供比**固定大小线程池**更好**的「排队性能」**（这种性能差异是因为使用了 `SynchronousQueue` 而不是 `LinkedBlockingQueue`。 在 `Java6` 中提供了一个新的 **非阻塞算法**来替代 `SynchronousQueue`，与 `Java5` 中的 `SynchronousQueue`相比，该算法把 `Executor` **基准的吞吐量**提高了 `3` 倍。）
>
> 当需要限制**当前任务数量**以满**足资源管理需求**时，可以选择**「固定大小」**的线程池，就像在接收**网络客户请求的服务器应用程序中**，如果不进行限制，那么很容易发生**过载**问题。

只有当任务**相互独立**时，为线程池或工作队列**设置界限**才是合理的。

如果任务之间存在`「依赖性」`，那么有界的线程池或队列就可能导致线程"饥饿"死锁问题。此时应该使用无界的线程池，例如 `newCachedThreadPool`。（对于提交其他任务并等待其结果的任务来说，还有一种方法就是使用有界的线程池，并使用 `SynchronousQueue` 作为工作队列，以及 **"调用者运行（Caller-Runs）"**`饱和策略`。

#### 8.3.3 饱和策略

**当有界队列被填满后，饱和策略开始发挥作用。**

`ThreadPoolExecutor` 的饱和策略可以通过调用 `setRejectedExecutionHandler` 来修改。（如果某个任务被提交到一个**已经关闭**的 `Executor`时，也会用到饱和策略。）

`JDK` 提供了几种不同的 `RejectedExecutionHandler`实现，每种实现都包含不同的**饱和策略**：

- `AbortPolicy`
- `CallerRunsPolicy`
- `DiscardPolicy`
- `DiscardOldestPolicy`

**中止（Abort）**策略是`「默认」`的饱和策略，该策略会抛出未检查的 `RejectedExecutionException`。

调用者可以捕获到这个异常，然后根据需求编写自己的处理代码。

当新提交的任务无法保存到队列中等待执行时`，"抛弃（Discard）"策略`会悄悄**抛弃**该任务。（如果工作队列是一个**「优先队列」**，`那么"抛弃最旧的"策略将导致抛弃优先级最高的任务`，因此最好`不要`将 "抛弃最旧的"「饱和策略」 和 优先级队列 在一起使用）

"`调用者运行（Caller-Runs）`" 策略实现了一种**「调节机制」**，该策略既不会抛弃任务，也不会抛出异常，而是将某些任务「回退」到调用者，从而降低新任务的流量。

它不会在线程池的某个线程中执行新提交的任务，而是在一个调用了 `executor` 的线程中执行该任务。我们可以将 `WebServer` 示例修改为使用**「有界队列」** 和 **"调用者运行" 饱和策略**，当线程池中的所有线程都被占用，并且工作队列被填满后，下一个任务会在调用 `executor` 时在 **「主线程」**中执行。

由于执行任务需要一定的时间，因此主线程至少在一段时间内不能提交任何任务，从而使得工作者线程有时间来处理正在执行的任务。

在这期间，主线程不会调用 `accept`，因此到达的请求将被保存在 `TCP` 层的队列中而不是在应用程序的队列中。

如果持续过载，那么 `TCP` 层将最终发现它的**「请求队列」**被填满，此时它同样会开始抛弃请求。

当服务**器「过载」**时，这种过载情况会逐渐向外蔓延 —— 从线程池到工作队列到应用程序再到TCP层，最终到达**「客户端」**，导致服务器在**「高负载」**下实现一种**平缓的性能降低**。

当创建 Executor 时，可以选择饱和策略或对执行策略进行修改。

`程序清单 8-3` 给出了如何创建一个**「固定」**大小的线程池，同时使用**"调用者运行" 饱和策略**。

```java
//创建固定大小的线程池
ThreadPoolExecutor executor = new ThreadPoolExecutor(N_THREADS, N_THREAD, 0L, TimeUnit.MILLISECONDS,new LinkedBlockingQueue<Runnable>(CAPACITY));

//设置调用者运行拒绝策略
executor.setRejectedExcutionHandler(new ThreadPoolExecutor.CallerRunsPolicy());
```



当工作队列被填满后，没有预定义的饱和策略来**「阻塞」** `execute`。 

然而通过使用 `Semaphore`（信号量）来**限制任务的到达率**就可以实现这个功能。

在程序清单 8-4 的 `BoundedExecutor` 中给出了这种实现。

该方法使用了一个**「无界队列」**（不能限制队列的大小和任务的到达率），并设置**信号量的上界**为「线程池的大小」 加上「可排队任务」的数量，这是因为**信号量需要控制「正在执行」和「等待执行」的「任务数量」**。

> `程序清单8-4` 使用 `Semaphore` 来控制任务的提交速率：

```java
// 使用 Semaphore 控制任务提交速率
public class BoundedExecutor {
    private final Executor exec;
    private final Semaphore semaphore;

    public BoundedExecutor(Executor exec, int bound) {
        this.exec = exec;
        this.semaphore = new Semaphore(bound);
    }

    public void submitTask(final Runnable command) throws InterruptedException {
        semaphore.acquire();
        try {
            exec.execute(() -> {
                try {
                    command.run();
                } finally {
                    semaphore.release();
                }
            });
        } catch (RejectedExecutionException e) {
            semaphore.release();
        }

    }
}

```

#### 8.3.4 线程工厂

每当**线程池需**要创建一个线程时，都通过线程工厂方法（详细参见 `程序清单 8-5`）来完成。

默认的「线程工厂」方法将创建一个新的、非守护线程，并且不包含特殊的配置信息。通过`指定`一个线程工厂方法，可以「定制」线程池的配置新。

在 `ThreadFactory` 中只定义了一个方法 `newThread`，每当线程池需要创建一个新线程时，都会调用这个方法。

使用定制线程工厂方法的场景：

- 为线程池中的线程指定一个 `UncaughtExceptionHandler`
- 实例化一个定制的 `Thread` 类用于执行调试信息的记录
- 修改线程的优先级或者守护状态（但这并不是一个好主意）。
- 修改线程池中线程的名称



> **程序清单 8-5** `ThreadFactory` 接口：

```java
public interface ThreadFactory {
    Thread newThread(Runnable r);
}
```



在`程序清单8-6` 的 `MyThreadFactory` 中给出了一个 **「自定义」** 的线程工厂。 它创建了一个新的 `MyAppThread` 实例，并将一个特定于线程池的名字传递给 `MyAppThread` 的构造函数，从而可以在线程转储和错误日志信息中区分来自「不同」线程池的线程。

在应用程序的**其他地方**也可以使用 `MyAppThread`，以便所有的线程都能使用它的调试功能。

> 程序清单 8-6 自定义的线程工厂

```java
// 自定义的线程工厂
public class MyThreadFactory implements ThreadFactory {
    private final String poolName;

    public MyThreadFactory(String poolName) {
        this.poolName = poolName;
    }

    @Override
    public Thread newThread(Runnable r) {
        return new MyAppThread(r, poolName);
    }
}

```



在 `MyAppThread` 中还可以定制其他行为，如程序清单 8-7 所示：

- 为线程指定名字
- 设置自定义的 `UncaughtExceptionHandler` 向 Logger 中写入信息
- 维护统计信息（包括有多少个线程被创建和销毁）



> `程序8-7` 定制Thread 基类：

```java
// 自定义的 Thread 基类

public class MyAppThread extends Thread {
    public static final String DEFAULT_NAME = "MyAppThread";
    public static volatile boolean debugLifecycle = false;
    public static final AtomicInteger created = new AtomicInteger();
    public static final AtomicInteger alive = new AtomicInteger();
    public static final Logger log = Logger.getAnonymousLogger();

    public MyAppThread(Runnable r) {
        this(r, DEFAULT_NAME);
    }

    public MyAppThread(Runnable r, String name) {
        super(r, name + "-" + created.incrementAndGet());
        setUncaughtExceptionHandler((t, e) -> {
            log.log(Level.SEVERE, "UNCAUGHT in thread" + t.getName(), e);
        });
    }

    /**
     * 运行时写入日志
     */
    @Override
    public void run() {
        // 复制 debug 标志 以确保一致的值
        boolean debug = debugLifecycle;
        if (debug) {
            log.log(Level.FINE, "Created" + getName());
        }
        try {
            alive.incrementAndGet();
            super.run();
        } finally {
            alive.decrementAndGet();
            if (debug) {
                log.log(Level.FINE, "Exiting" + getName());
            }
        }
    }

    public static int getThreadsCreated() {
        return created.get();
    }

    public static int getThreadsAlive() {
        return alive.get();
    }

    public static boolean getDebug() {
        return debugLifecycle;
    }

    public static void setDebug(boolean b) {
        debugLifecycle = b;
    }
}

```

如果在应用程序中需要利用安全策略来控制对某些特殊代码库的访问权限，那么可以通过 `Executor` 中的 `privilegedThreadFactory` 工厂来定制自己的线程工厂。

通过这种方式创建出来的线程，将与创建 `privilegedThreadFactory` 的线程拥有相同的访问权限、`AccessControlContext` 和 `contextClassLoader`。

如果不使用 `privilegedThreadFacotry`，线程池创建的线程将在需要新线程时调用 `execute` 或 `submit` 的客户程序中继承访问权限，从而导致令人困惑的安全性异常。

#### 8.3.5 在调用构造函数后再定制 ThreadPoolExecutor

在调用完 ThreadPoolExecutor 构造函数后，



### 8.4 扩展 ThreadPoolExecutor



### 8.5 递归算法的并行化

​	